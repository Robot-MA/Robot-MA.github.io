<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Manipulate Anything</title>
    <meta name="description" content="Manipulate-Anything: Automating Real-World Robots using Vision-Language Models">
    <meta name="keywords" content="Zero-shot manipulation, Multimodal language models">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <style type="text/css">
        #simulation-result-video {
            width: 50%;
            height: auto;
        }
        #peract-simulation-result-video {
            width: 75%;
            height: auto;
        }
    </style>

    <script>
        function init() {
            const video = document.getElementById("simulation-result-video");
            video.addEventListener("error", () => {
                console.log("Error loading video: ", video.src), ". Setting default to none";
                if(video.src.includes("undefined")) {
                    console.log("Don't have an undefined version of the clip, just crash");
                    return;
                }
                const method = document.getElementById("single-menu-methods").value;
                const uri = "static/videos/simulation/" + method + "/undefined.mp4"
                video.src = uri;
                video.playbackRate = 1.75;
                video.play();
            }, true);

            const video_peract = document.getElementById("peract-simulation-result-video");
            video_peract.addEventListener("error", () => {
                console.log("Error loading video: ", video_peract.src), ". Setting default to none";
                if(video_peract.src.includes("undefined")) {
                    console.log("Don't have an undefined version of the clip, just crash");
                    return;
                }
                const method = document.getElementById("peract-single-menu-methods").value;
                const uri = "static/videos/simulation_peract/" + method + "/undefined.mp4"
                video_peract.src = uri;
                video_peract.playbackRate = 1.75;
                video_peract.play();
            }, true);
        }
        function updateSimulationGeneratedDataVideo() {
            const task = document.getElementById("single-menu-tasks").value;
            const method = document.getElementById("single-menu-methods").value;
            const video = document.getElementById("simulation-result-video");
            const uri = "static/videos/simulation/" + method + "/" + task + ".mp4"
            video.src = uri;
            video.playbackRate = 1.75;
            video.play();
        }
        function updatePerActTrainedVideo() {
            const task = document.getElementById("peract-single-menu-tasks").value;
            const method = document.getElementById("peract-single-menu-methods").value;
            const video = document.getElementById("peract-simulation-result-video");
            const uri = "static/videos/simulation_peract/" + method + "/" + task + ".mp4"
            video.src = uri;
            video.playbackRate = 1.75;
            video.play();

        }
    </script>
</head>

<body onload="init(); updateSimulationGeneratedDataVideo();">
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            Manipulate-Anything: <br> Automating Real-World Robots using Vision-Language Models
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="https://duanjiafei.com/">Jiafei Duan</a><sup>*</sup><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://wentaoyuan.github.io/">Wentao Yuan</a><sup>*</sup><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://wpumacay.github.io/">Wilbert Pumacay</a><sup>4</sup>
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://helen9975.github.io/">Yi Ru Wang</a><sup>1</sup>
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://ehsanik.github.io/">Kiana Ehsani</a><sup>3</sup>
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a><sup>1, 2</sup>
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://ranjaykrishna.com/index.html/">Ranjay Krishna</a><sup>1, 3</sup>
                            </span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>University of Washington</span>
                            <span class="author-block"><sup>2</sup>NVIDIA</span>
                            <br>
                            <span class="author-block"><sup>3</sup>Allen Institute for Artifical Intelligence</span>
                            <span class="author-block"><sup>4</sup>Universidad Católica San Pablo</span>
                        </div>
                        <div class="footnote">
                            <p>* Equal contribution</p>
                        </div>
                        <div class="column has-text-centered">
                            <!-- Local path link -->
                            <span class="link-block">
                                <a target="_blank" href="MA_paper.pdf" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-file"></i></span>
                                    <span>Paper</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a target="_blank" href="https://robot-ma.github.io/" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fab fa-github"></i></span>
                                    <span>Code[Coming soon]</span>
                                </a>
                            </span>
                            <!-- Supplementary material link -->
                            <span class="link-block">
                                <a target="_blank" href="supplementary_material.pdf" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-file"></i></span>
                                    <span>Sup. Material</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a target="_blank" href="https://drive.google.com/drive/folders/1bq3P8ywJkFMxemq9ywvj2b7LHsAhx2kg?usp=sharing" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-robot"></i></span>
                                    <span>MA generated data</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <!-- Video teaser -->
                <video id="teaser" autoplay muted loop height="100">
                    <source src="static/videos/video_teaser.mp4" type="video/mp4">
                </video>
                <!-- !Video teaser -->
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Large-scale endeavors like RT-1[1] and widespread community efforts
                            such as Open-X-Embodiment have contributed to growing the scale of robot
                            demonstration data. However, there is still an opportunity to improve the quality,
                            quantity, and diversity of robot demonstration data. Although vision-language
                            models have been shown to automatically generate demonstration data, their utility
                            has been limited to environments with privileged state information, they require
                            hand-designed skills, and are limited to interactions with few object instances. We
                            propose MANIPULATE-ANYTHING, a scalable automated generation method for
                            real-world robotic manipulation. Unlike prior work, our method can operate in
                            real-world environments without any privileged state information, hand-designed
                            skills, and can manipulate any static object. We evaluate our method using two
                            setups. First, MANIPULATE-ANYTHING successfully generates trajectories for all
                            7 real-world and 14 simulation tasks, significantly outperforming existing methods
                            like VoxPoser. Second, MANIPULATE-ANYTHING’s demonstrations can train
                            more robust behavior cloning policies than training with human demonstrations,
                            or from data generated by VoxPoser, Scaling-up-Distilling-Down and Code-As-Policies
                            [5]. We believe MANIPULATE-ANYTHING can be the scalable method for both
                            generating data for robotics and solving novel tasks in a zero-shot setting
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->
        </div>
    </section>

    <!-- Real-world Results -->
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Real World Experiments</h2>
                <div class="column has-text-centered">
                    <h3 class="title is-5">Manipulate-Anything</h3>
                </div>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve">
                        <video id="steve" autoplay muted loop>
                            <source src="static/videos/real_world/Turn_on_lamp_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-fullbody">
                        <video id="fullbody" autoplay muted loop>
                            <source src="static/videos/real_world/open_drawer_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-shiba">
                        <video id="shiba" autoplay muted loop>
                            <source src="static/videos/real_world/sort_obj_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-ender">
                        <video id="ender" autoplay muted loop>
                            <source src="static/videos/real_world/open_jar_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <!--<div class="item item-kirby">
                        <video id="kirby" autoplay muted loop>
                            <source src="static/videos/real_world/pull_knife_filled.mp4" type="video/mp4">
                        </video>
                    </div>-->
                    <div class="item item-pokemon">
                        <video id="pokemon" autoplay muted loop>
                            <source src="static/videos/real_world/set_dice_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-chansey">
                        <video id="chansey" autoplay muted loop>
                            <source src="static/videos/real_world/close_laptop_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-pikachu">
                        <video id="pikachu" autoplay muted loop>
                            <source src="static/videos/real_world/press_switch_filled.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- /Real-world Results -->

    <!-- Simulation generated data -->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <br/>
                        <br/>
                        <h2 class="title is-3">Simulation</h2>
                        <div class="columns">
                            <div class="column has-text-centered">
                                <h3 class="title is-5">Zero-shot Generated data</h3>
                                Method
                                <div class="select is-small">
                                    <select id="single-menu-methods" onchange="updateSimulationGeneratedDataVideo()">
                                        <option value="manipulate_anything" selected="selected">Manipulate Anything</option>
                                        <option value="voxposer">Voxposer</option>
                                        <option value="code_as_policies">Code as policies</option>
                                        <option value="scaling_up">Scaling Up</option>
                                        <option value="rlbench">Rlbench</option>
                                    </select>
                                </div>
                                applied to task
                                <div class="select is-small">
                                    <select id="single-menu-tasks" onchange="updateSimulationGeneratedDataVideo()">
                                        <option value="play_jenga_mod" selected="selected">insert block</option>
                                        <option value="slide_block_mod">push block</option>
                                        <option value="pick_and_lift">pick and lift</option>
                                        <option value="close_box">close box</option>
                                        <option value="lamp_on">lamp on</option>
                                        <option value="open_box">open box</option>
                                        <option value="open_jar">open jar</option>
                                        <option value="open_wine">open wine</option>
                                        <option value="pick_up_cup">pick up cup</option>
                                        <option value="play_jenga">play jenga</option>
                                        <option value="put_block">put block</option>
                                        <option value="put_knife">put knife</option>
                                        <option value="sort_mustard">sort mustard</option>
                                        <option value="take_umbrella">take umbrella</option>
                                    </select>
                                </div>
                                <br/>
                                <br/>
                                <video id="simulation-result-video" muted autoplay loop>
                                    <source src="static/videos/simulation/manipulate_anything/pick_and_lift.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- /Simulation generated data -->

    <!-- Simulation PERACT training -->
    <section class="section">
        <div class="container is-max-widescreen">
            <div class="rows">
                <div class="rows is-centered ">
                    <div class="row is-full-width">
                        <div class="columns">
                            <div class="column has-text-centered">
                                <h3 class="title is-5">Policy distilled from different data generation</h3>
                                Method
                                <div class="select is-small">
                                    <select id="peract-single-menu-methods" onchange="updatePerActTrainedVideo()">
                                        <option value="manipulate_anything" selected="selected">Manipulate Anything</option>
                                        <option value="rlbench">Rlbench</option>
                                        <option value="voxposer">Voxposer</option>
                                        <option value="code_as_policies">Code as Policies</option>
                                    </select>
                                </div>
                                generated data for task
                                <div class="select is-small">
                                    <select id="peract-single-menu-tasks" onchange="updatePerActTrainedVideo()">
                                        <option value="pick_and_lift" selected="selected">pick and lift</option>
                                        <option value="close_box">close box</option>
                                        <option value="lamp_on">lamp on</option>
                                        <option value="open_box">open box</option>
                                        <option value="open_jar">open jar</option>
                                        <option value="open_wine">open wine</option>
                                        <option value="pick_up_cup">pick up cup</option>
                                        <option value="play_jenga">play jenga</option>
                                        <option value="put_block">put block</option>
                                        <option value="put_knife">put knife</option>
                                        <option value="sort_mustard">sort mustard</option>
                                        <option value="take_umbrella">take umbrella</option>
                                    </select>
                                </div>
                                <br/>
                                <br/>
                                <video id="peract-simulation-result-video" muted autoplay loop>
                                    <source src="static/videos/simulation_peract/rlbench/pick_and_lift.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- /Simulation PERACT training -->

    <!-- Image MA_Framework -->
    <section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Manipulate-Anything Framework</h2>
                <img src="static/images/teaser_new.png" />
                <p class="caption">MANIPULATE-ANYTHING is an automated method for robot manipulation in real world
                    environments. Unlike prior methods, it does not require privileged state information, hand-designed
                    skills, or limited to manipulating a fixed number of object instances. It can guide a robot to accomplish
                    a diverse set of unseen tasks, manipulating diverse objects. Furthermore, the generated data enables
                    training behavior cloning policies that outperform training with human demonstrations.</p>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Manipulate-Anything System Overview</h2>
                    <img src="static/images/overview.png" />
                    <p class="caption">Begins by inputting a scene representation
                        and a natural language task instruction into a VLM, which identifies objects and determines sub-tasks.
                        For each sub-task, we provide multi-view images, verification conditions, and task goals to the action
                        generation module, producing a task-specific grasp pose or action code. This leads to a temporary
                        goal state, assessed by the sub-task verification module for error recovery. Once all sub-tasks are
                        achieved, we filter the trajectories to obtain successful demonstrations for downstream policy training.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- /Image MA_Framework -->

    <!-- Image MA_Action_Generation_Module -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Zero-shot empirical results</h2>
                    <img src="static/images/zero-shot.png" />
                    <p class="caption">MANIPULATE-ANYTHING
                        outperformed other baselines in 10 out of 14 simulation tasks from RLBench. Each task was
                        evaluated over 3 seeds to obtain the task-averaged success rate and standard deviations.</p>
                </div>
            </div>
        </div>
    </section>
    <!-- /Image MA_Action_Generation_Module -->

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">BC with zero-shot data generation methods</h2>
                    <img src="static/images/distill.png" />
                    <p class="caption">The behavior cloning policy trained
                        on the data generated by MANIPULATE-ANYTHING provides the best performance on 10 out of 12
                        tasks compared to the other autonomous data generation baselines. We report the Success Rate %
                        for behaviour cloning policies trained with data generated from VoxPoser and Code as Policies
                        in comparison. Note that the RLBench baseline uses human expert demonstrations and is
                        considered an upper bound for behavior cloning.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Image MA_Action_Distribution -->
    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Action Distribution</h2>
                    <img src="static/images/img_action_distribution.png" />
                    <p class="caption">We compare the action distribution of data
                        generated by various methods against human-generated demonstrations via RLBench on the same
                        set of tasks. We observed a high similarity between the distribution of our generated data and the
                        human-generated data. This is further supported by the computed CD between our methods and the
                        RLBench data, which yields the lowest (CD=0.056).</p>
                </div>
            </div>
        </div>
    </section>
    <!-- /Image MA_Action_Distribution -->
    <section class="section" id="BibTeX">
        <div class="container is-max-widescreen content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@article{duan2024manipulate,
        title={Manipulate-Anything: Automating Real-World Robots using Vision-Language Models}, 
        author={Duan, Jiafei and Yuan, Wentao and Pumacay, Wilbert and Wang, Yi Ru and Ehsani, Kiana and Fox, Dieter and Krishna, Ranjay},
        journal={arXiv preprint arXiv:2406.18915},
        year={2024}
        }</code></pre>
        </div>
      </section>

</body>
</html>
